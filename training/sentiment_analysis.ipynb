{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "beaed3b0",
   "metadata": {},
   "source": [
    "# Sentiment Analysis\n",
    "\n",
    "In this notebook it is showed the workflow of how we built the sentiment analysis model to classify the polarity of the financial tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ade0884",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "import joblib\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from imblearn.datasets import make_imbalance\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1a0006",
   "metadata": {},
   "source": [
    "We used two different datasets of financial tweets to train and test our model:\n",
    "the first dataset was downloaded from Kaggle at the following link and it contains labelled tweets ;\n",
    "the test set includes real tweets that were scraped form Twitter and that we manually classified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ec786d91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>video offic mind busi david solomon tell gs in...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>price lumber lb f sinc hit ytd high maci turna...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>say american dream dead</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>barri silbert extrem optimist bitcoin predict ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>satellit avoid attack space junk circl earth paid</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28435</th>\n",
       "      <td>fb c f f cb ecf</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28436</th>\n",
       "      <td>btc</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28437</th>\n",
       "      <td>rt hd nuff said tel telcoin telfam crypto bloc...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28438</th>\n",
       "      <td>btc</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28439</th>\n",
       "      <td>stellar xlm price binanc registr open limit time</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28440 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text    target\n",
       "0      video offic mind busi david solomon tell gs in...   neutral\n",
       "1      price lumber lb f sinc hit ytd high maci turna...   neutral\n",
       "2                                say american dream dead  negative\n",
       "3      barri silbert extrem optimist bitcoin predict ...  positive\n",
       "4      satellit avoid attack space junk circl earth paid  negative\n",
       "...                                                  ...       ...\n",
       "28435                                    fb c f f cb ecf   neutral\n",
       "28436                                                btc   neutral\n",
       "28437  rt hd nuff said tel telcoin telfam crypto bloc...   neutral\n",
       "28438                                                btc   neutral\n",
       "28439   stellar xlm price binanc registr open limit time   neutral\n",
       "\n",
       "[28440 rows x 2 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from preprocessing.tweet_cleaner import tweet_pruning, remove_special_char\n",
    "\n",
    "train_data = pd.read_csv('./data/tweets_with_sentiment.csv')\n",
    "\n",
    "# Preprocessing\n",
    "train_data['text'] = train_data['text'].astype(str)\n",
    "train_data['text'] = train_data['text'].str.lower()\n",
    "train_data['text'] = train_data['text'].apply(remove_special_char)\n",
    "\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5d28b9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Spot-Check Algorithms\n",
    "classifiers = [\n",
    "    RandomForestClassifier(n_estimators=200, min_samples_split=200, max_features = 3, random_state=1, max_depth=3),\n",
    "    XGBClassifier(),\n",
    "    AdaBoostClassifier(),\n",
    "    KNeighborsClassifier(3),\n",
    "    LogisticRegression(),\n",
    "    MultinomialNB(),\n",
    "    BernoulliNB\n",
    "]\n",
    "\n",
    "# Pipeline Classifier\n",
    "pipelines = []\n",
    "\n",
    "for classifier in classifiers:\n",
    "    \n",
    "    pipelines.append(Pipeline([\n",
    "        ('vect', CountVectorizer()),\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "        ('clf', classifier)\n",
    "    ]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5a74a22e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before undersampling:  Counter({'neutral': 13883, 'positive': 6785, 'negative': 2084})\n",
      "After undersampling:  Counter({'neutral': 13883, 'positive': 6785, 'negative': 2084})\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(train_data['text'], train_data['target'], test_size=0.2, random_state=11)\n",
    "\n",
    "print(\"Before undersampling: \", Counter(y_train))\n",
    "\n",
    "# Convert x_train to np_array for rebalance\n",
    "#x_train = x_train.values.reshape(-1, 1)\n",
    "#x_train, y_train = make_imbalance(x_train, y_train,\n",
    "                                  #sampling_strategy={'positive': 2000, 'neutral': 2000, 'negative': 2000},\n",
    "                                  #random_state=0)\n",
    "\n",
    "# Return to pandas series\n",
    "x_train = pd.Series(np.squeeze(x_train))\n",
    "print(\"After undersampling: \", Counter(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "adf60d6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Evaluation:  RandomForestClassifier(max_depth=3, max_features=3, min_samples_split=200,\n",
      "                       n_estimators=200, random_state=1)\n",
      "Accuracy on test set:  0.6060126582278481\n",
      "Metrics per class on test set:\n",
      "Confusion matrix:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00       514\n",
      "     neutral       0.61      1.00      0.75      3447\n",
      "    positive       0.00      0.00      0.00      1727\n",
      "\n",
      "    accuracy                           0.61      5688\n",
      "   macro avg       0.20      0.33      0.25      5688\n",
      "weighted avg       0.37      0.61      0.46      5688\n",
      "\n",
      "[19:07:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "\n",
      " Evaluation:  XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
      "              gamma=0, gpu_id=-1, importance_type=None,\n",
      "              interaction_constraints='', learning_rate=0.300000012,\n",
      "              max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
      "              monotone_constraints='()', n_estimators=100, n_jobs=8,\n",
      "              num_parallel_tree=1, objective='multi:softprob', predictor='auto',\n",
      "              random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=None,\n",
      "              subsample=1, tree_method='exact', validate_parameters=1,\n",
      "              verbosity=None)\n",
      "Accuracy on test set:  0.954817158931083\n",
      "Metrics per class on test set:\n",
      "Confusion matrix:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.81      0.87       514\n",
      "     neutral       0.95      0.99      0.97      3447\n",
      "    positive       0.98      0.93      0.95      1727\n",
      "\n",
      "    accuracy                           0.95      5688\n",
      "   macro avg       0.95      0.91      0.93      5688\n",
      "weighted avg       0.96      0.95      0.95      5688\n",
      "\n",
      "\n",
      " Evaluation:  AdaBoostClassifier()\n",
      "Accuracy on test set:  0.9040084388185654\n",
      "Metrics per class on test set:\n",
      "Confusion matrix:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.66      0.77       514\n",
      "     neutral       0.89      0.97      0.93      3447\n",
      "    positive       0.94      0.84      0.89      1727\n",
      "\n",
      "    accuracy                           0.90      5688\n",
      "   macro avg       0.92      0.82      0.86      5688\n",
      "weighted avg       0.91      0.90      0.90      5688\n",
      "\n",
      "\n",
      " Evaluation:  KNeighborsClassifier(n_neighbors=3)\n",
      "Accuracy on test set:  0.8088959212376934\n",
      "Metrics per class on test set:\n",
      "Confusion matrix:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.69      0.51      0.58       514\n",
      "     neutral       0.80      0.94      0.86      3447\n",
      "    positive       0.88      0.65      0.74      1727\n",
      "\n",
      "    accuracy                           0.81      5688\n",
      "   macro avg       0.79      0.70      0.73      5688\n",
      "weighted avg       0.81      0.81      0.80      5688\n",
      "\n",
      "\n",
      " Evaluation:  LogisticRegression()\n",
      "Accuracy on test set:  0.9319620253164557\n",
      "Metrics per class on test set:\n",
      "Confusion matrix:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.68      0.79       514\n",
      "     neutral       0.92      0.98      0.95      3447\n",
      "    positive       0.96      0.91      0.93      1727\n",
      "\n",
      "    accuracy                           0.93      5688\n",
      "   macro avg       0.94      0.86      0.89      5688\n",
      "weighted avg       0.93      0.93      0.93      5688\n",
      "\n",
      "\n",
      " Evaluation:  MultinomialNB()\n",
      "Accuracy on test set:  0.820323488045007\n",
      "Metrics per class on test set:\n",
      "Confusion matrix:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.23      0.38       514\n",
      "     neutral       0.79      0.96      0.87      3447\n",
      "    positive       0.88      0.72      0.79      1727\n",
      "\n",
      "    accuracy                           0.82      5688\n",
      "   macro avg       0.88      0.64      0.68      5688\n",
      "weighted avg       0.84      0.82      0.80      5688\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "_BaseDiscreteNB.fit() missing 1 required positional argument: 'y'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_14608/1576024477.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mpipe\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mpipelines\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m     \u001B[1;31m# Training the Pipeline Classifier\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 6\u001B[1;33m     \u001B[0mpipe\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx_train\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_train\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      7\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      8\u001B[0m     \u001B[1;31m# Testing of the Pipeline\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\pipeline.py\u001B[0m in \u001B[0;36mfit\u001B[1;34m(self, X, y, **fit_params)\u001B[0m\n\u001B[0;32m    392\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_final_estimator\u001B[0m \u001B[1;33m!=\u001B[0m \u001B[1;34m\"passthrough\"\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    393\u001B[0m                 \u001B[0mfit_params_last_step\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mfit_params_steps\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msteps\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;33m-\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 394\u001B[1;33m                 \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_final_estimator\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mXt\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mfit_params_last_step\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    395\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    396\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mTypeError\u001B[0m: _BaseDiscreteNB.fit() missing 1 required positional argument: 'y'"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "for pipe in pipelines:\n",
    "    # Training the Pipeline Classifier\n",
    "    pipe.fit(x_train, y_train)\n",
    "\n",
    "    # Testing of the Pipeline\n",
    "    predicted = pipe.predict(x_test)\n",
    "\n",
    "    # Extracting statistics and metrics\n",
    "    print(\"\\n Evaluation: \", pipe['clf'])\n",
    "    accuracy = accuracy_score(predicted, y_test)\n",
    "    print(\"Accuracy on test set: \", accuracy)\n",
    "    print(\"Metrics per class on test set:\")\n",
    "\n",
    "    print(\"Confusion matrix:\")\n",
    "    metrics.confusion_matrix(y_test, predicted)\n",
    "\n",
    "    print(metrics.classification_report(y_test, predicted, target_names=[\"negative\", \"neutral\", \"positive\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0007fbd9",
   "metadata": {},
   "source": [
    "XGBoost Classifier has the best performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21248433",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the classifier\n",
    "filename = '../model/sentiment_classifier.pkl'\n",
    "joblib.dump(pipelines[1], filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75091665",
   "metadata": {},
   "source": [
    "The performance using Kaggle dataset were excellente but we want to test our model also with tweets that we scraped directly from Twitter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e50cae70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Tweets:  Counter({'neutral': 566, 'positive': 143, 'negative': 50})\n",
      "Accuracy on test set:  0.7901234567901234\n",
      "Metrics per class on test set:\n",
      "Confusion matrix:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.63      0.71        43\n",
      "     neutral       0.83      0.90      0.86        70\n",
      "    positive       0.72      0.78      0.75        49\n",
      "\n",
      "    accuracy                           0.79       162\n",
      "   macro avg       0.79      0.77      0.77       162\n",
      "weighted avg       0.79      0.79      0.79       162\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipe = joblib.load('../model/sentiment_classifier.pkl')\n",
    "\n",
    "# Testing with real tweets\n",
    "real_tweets = pd.read_json('../data/train/tweets_with_label.json')\n",
    "print(\"Number of Tweets: \", Counter(real_tweets['target']))\n",
    "\n",
    "# Preprocessing\n",
    "real_tweets = real_tweets.rename(columns={'text': 'Text'})\n",
    "real_tweets['Text'] = real_tweets['Text'].str.lower()\n",
    "real_tweets = tweet_pruning(real_tweets, 'amazon', 'AMZN')\n",
    "real_tweets['Text'] = real_tweets['Text'].apply(remove_special_char)\n",
    "\n",
    "# Predicting\n",
    "predicted = pipe.predict(real_tweets['Text'].values)\n",
    "\n",
    "# Extracting statistics and metrics\n",
    "accuracy = accuracy_score(real_tweets['target'], predicted)\n",
    "print(\"Accuracy on test set: \", accuracy)\n",
    "print(\"Metrics per class on test set:\")\n",
    "\n",
    "print(\"Confusion matrix:\")\n",
    "metrics.confusion_matrix(real_tweets['target'].values, predicted)\n",
    "\n",
    "print(metrics.classification_report(real_tweets['target'].values, predicted, target_names=[\"negative\", \"neutral\", \"positive\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f3d659e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}