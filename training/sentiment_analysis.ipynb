{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "beaed3b0",
   "metadata": {},
   "source": [
    "# Sentiment Analysis\n",
    "\n",
    "In this notebook it is showed the workflow of how we built the sentiment analysis model to classify the polarity of the financial tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ade0884",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "import joblib\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from imblearn.datasets import make_imbalance\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1a0006",
   "metadata": {},
   "source": [
    "We used two different datasets of financial tweets to train and test our model:\n",
    "the first dataset was downloaded from Kaggle at the following link and it contains labelled tweets ;\n",
    "the test set includes real tweets that were scraped form Twitter and that we manually classified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec786d91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>video offic mind busi david solomon tell gs in...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>price lumber lb f sinc hit ytd high maci turna...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>say american dream dead</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>barri silbert extrem optimist bitcoin predict ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>satellit avoid attack space junk circl earth paid</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28435</th>\n",
       "      <td>fb c f f cb ecf</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28436</th>\n",
       "      <td>btc</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28437</th>\n",
       "      <td>rt hd nuff said tel telcoin telfam crypto bloc...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28438</th>\n",
       "      <td>btc</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28439</th>\n",
       "      <td>stellar xlm price binanc registr open limit time</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28440 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text    target\n",
       "0      video offic mind busi david solomon tell gs in...   neutral\n",
       "1      price lumber lb f sinc hit ytd high maci turna...   neutral\n",
       "2                                say american dream dead  negative\n",
       "3      barri silbert extrem optimist bitcoin predict ...  positive\n",
       "4      satellit avoid attack space junk circl earth paid  negative\n",
       "...                                                  ...       ...\n",
       "28435                                    fb c f f cb ecf   neutral\n",
       "28436                                                btc   neutral\n",
       "28437  rt hd nuff said tel telcoin telfam crypto bloc...   neutral\n",
       "28438                                                btc   neutral\n",
       "28439   stellar xlm price binanc registr open limit time   neutral\n",
       "\n",
       "[28440 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from preprocessing.tweet_cleaner import tweet_pruning, remove_special_char\n",
    "\n",
    "train_data = pd.read_csv('./data/tweets_with_sentiment.csv')\n",
    "\n",
    "# Preprocessing\n",
    "train_data['text'] = train_data['text'].astype(str)\n",
    "train_data['text'] = train_data['text'].str.lower()\n",
    "train_data['text'] = train_data['text'].apply(remove_special_char)\n",
    "\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d28b9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Spot-Check Algorithms\n",
    "classifiers = [\n",
    "    RandomForestClassifier(),\n",
    "    XGBClassifier(eval_metric='mlogloss'),\n",
    "    AdaBoostClassifier(),\n",
    "    KNeighborsClassifier(),\n",
    "    LogisticRegression(),\n",
    "    MultinomialNB(),\n",
    "    BernoulliNB()\n",
    "]\n",
    "\n",
    "# Pipeline Classifier\n",
    "pipelines = []\n",
    "\n",
    "for classifier in classifiers:\n",
    "    \n",
    "    pipelines.append(Pipeline([\n",
    "        ('vect', CountVectorizer()),\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "        ('clf', classifier)\n",
    "    ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a74a22e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16012/2302304336.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Before undersampling: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCounter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# Convert x_train to np_array for rebalance\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#x_train = x_train.values.reshape(-1, 1)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#x_train, y_train = make_imbalance(x_train, y_train,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_train' is not defined"
     ]
    }
   ],
   "source": [
    "#print(\"Before undersampling: \", Counter(y_train))\n",
    "\n",
    "# Convert x_train to np_array for rebalance\n",
    "#x_train = x_train.values.reshape(-1, 1)\n",
    "#x_train, y_train = make_imbalance(x_train, y_train,\n",
    "                                  #sampling_strategy={'positive': 2000, 'neutral': 2000, 'negative': 2000},\n",
    "                                  #random_state=0)\n",
    "\n",
    "# Return to pandas series\n",
    "#x_train = pd.Series(np.squeeze(x_train))\n",
    "#print(\"After undersampling: \", Counter(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adf60d6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Evaluation:  RandomForestClassifier()  \tTraining time:  15.845623230934143\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.82      0.89      2598\n",
      "     neutral       0.96      0.98      0.97     17330\n",
      "    positive       0.96      0.95      0.96      8512\n",
      "\n",
      "    accuracy                           0.96     28440\n",
      "   macro avg       0.96      0.92      0.94     28440\n",
      "weighted avg       0.96      0.96      0.96     28440\n",
      "\n",
      "\n",
      " Evaluation:  XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, eval_metric='mlogloss', gamma=None,\n",
      "              gpu_id=None, importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None)  \tTraining time:  10.22232253551483\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.77      0.84      2598\n",
      "     neutral       0.93      0.98      0.96     17330\n",
      "    positive       0.97      0.92      0.94      8512\n",
      "\n",
      "    accuracy                           0.94     28440\n",
      "   macro avg       0.94      0.89      0.91     28440\n",
      "weighted avg       0.95      0.94      0.94     28440\n",
      "\n",
      "\n",
      " Evaluation:  AdaBoostClassifier()  \tTraining time:  3.01286518573761\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.61      0.73      2598\n",
      "     neutral       0.86      0.98      0.92     17330\n",
      "    positive       0.95      0.79      0.86      8512\n",
      "\n",
      "    accuracy                           0.89     28440\n",
      "   macro avg       0.91      0.79      0.84     28440\n",
      "weighted avg       0.89      0.89      0.88     28440\n",
      "\n",
      "\n",
      " Evaluation:  KNeighborsClassifier()  \tTraining time:  2.204296588897705\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.30      0.42      2598\n",
      "     neutral       0.71      0.95      0.81     17330\n",
      "    positive       0.85      0.41      0.55      8512\n",
      "\n",
      "    accuracy                           0.73     28440\n",
      "   macro avg       0.75      0.55      0.59     28440\n",
      "weighted avg       0.75      0.73      0.70     28440\n",
      "\n",
      "\n",
      " Evaluation:  LogisticRegression()  \tTraining time:  2.133932042121887\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.64      0.76      2598\n",
      "     neutral       0.90      0.98      0.94     17330\n",
      "    positive       0.95      0.88      0.91      8512\n",
      "\n",
      "    accuracy                           0.92     28440\n",
      "   macro avg       0.93      0.83      0.87     28440\n",
      "weighted avg       0.92      0.92      0.91     28440\n",
      "\n",
      "\n",
      " Evaluation:  MultinomialNB()  \tTraining time:  0.42577662467956545\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.20      0.33      2598\n",
      "     neutral       0.78      0.96      0.86     17330\n",
      "    positive       0.85      0.66      0.74      8512\n",
      "\n",
      "    accuracy                           0.80     28440\n",
      "   macro avg       0.86      0.60      0.64     28440\n",
      "weighted avg       0.82      0.80      0.77     28440\n",
      "\n",
      "\n",
      " Evaluation:  BernoulliNB()  \tTraining time:  0.4354691982269287\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.40      0.52      2598\n",
      "     neutral       0.86      0.89      0.88     17330\n",
      "    positive       0.80      0.84      0.82      8512\n",
      "\n",
      "    accuracy                           0.83     28440\n",
      "   macro avg       0.79      0.71      0.74     28440\n",
      "weighted avg       0.83      0.83      0.83     28440\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "for pipe in pipelines:\n",
    "    t0 = time.time()\n",
    "    predicted = cross_val_predict(pipe, train_data['text'], train_data['target'], cv=10)\n",
    "    t1 = time.time()\n",
    "    t = (t1-t0)/10\n",
    "    \n",
    "    print(\"\\n Evaluation: \", pipe['clf'], \" \\tTraining time: \", t)\n",
    "    print(metrics.classification_report(train_data['target'], predicted, target_names=[\"negative\", \"neutral\", \"positive\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e95e813",
   "metadata": {},
   "source": [
    "The performance using Kaggle dataset were excellent but we want to test our model also with tweets that we scraped directly from Twitter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5dddec45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Tweets:  Counter({'neutral': 566, 'positive': 143, 'negative': 50})\n",
      "\n",
      " Evaluation:  RandomForestClassifier()  \tPrediction time:  0.04288935661315918\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.58      0.66        43\n",
      "     neutral       0.83      0.85      0.84        71\n",
      "    positive       0.69      0.82      0.75        50\n",
      "\n",
      "    accuracy                           0.77       164\n",
      "   macro avg       0.76      0.75      0.75       164\n",
      "weighted avg       0.77      0.77      0.77       164\n",
      "\n",
      "\n",
      " Evaluation:  XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
      "              eval_metric='mlogloss', gamma=0, gpu_id=-1, importance_type=None,\n",
      "              interaction_constraints='', learning_rate=0.300000012,\n",
      "              max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
      "              monotone_constraints='()', n_estimators=100, n_jobs=8,\n",
      "              num_parallel_tree=1, objective='multi:softprob', predictor='auto',\n",
      "              random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=None,\n",
      "              subsample=1, tree_method='exact', validate_parameters=1,\n",
      "              verbosity=None)  \tPrediction time:  0.02593207359313965\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.88      0.84        43\n",
      "     neutral       0.84      0.89      0.86        71\n",
      "    positive       0.90      0.76      0.83        50\n",
      "\n",
      "    accuracy                           0.85       164\n",
      "   macro avg       0.85      0.84      0.84       164\n",
      "weighted avg       0.85      0.85      0.85       164\n",
      "\n",
      "\n",
      " Evaluation:  AdaBoostClassifier()  \tPrediction time:  0.019915103912353516\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.51      0.68        43\n",
      "     neutral       0.72      0.92      0.81        71\n",
      "    positive       0.71      0.74      0.73        50\n",
      "\n",
      "    accuracy                           0.76       164\n",
      "   macro avg       0.81      0.72      0.74       164\n",
      "weighted avg       0.79      0.76      0.75       164\n",
      "\n",
      "\n",
      " Evaluation:  KNeighborsClassifier(n_neighbors=3)  \tPrediction time:  0.12167716026306152\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        43\n",
      "     neutral       0.43      1.00      0.60        71\n",
      "    positive       0.00      0.00      0.00        50\n",
      "\n",
      "    accuracy                           0.43       164\n",
      "   macro avg       0.14      0.33      0.20       164\n",
      "weighted avg       0.19      0.43      0.26       164\n",
      "\n",
      "\n",
      " Evaluation:  LogisticRegression()  \tPrediction time:  0.007972002029418945\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.44      0.58        43\n",
      "     neutral       0.63      0.92      0.75        71\n",
      "    positive       0.62      0.48      0.54        50\n",
      "\n",
      "    accuracy                           0.66       164\n",
      "   macro avg       0.70      0.61      0.62       164\n",
      "weighted avg       0.69      0.66      0.64       164\n",
      "\n",
      "\n",
      " Evaluation:  MultinomialNB()  \tPrediction time:  0.006981611251831055\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        43\n",
      "     neutral       0.55      0.58      0.57        71\n",
      "    positive       0.44      0.78      0.57        50\n",
      "\n",
      "    accuracy                           0.49       164\n",
      "   macro avg       0.33      0.45      0.38       164\n",
      "weighted avg       0.37      0.49      0.42       164\n",
      "\n",
      "\n",
      " Evaluation:  BernoulliNB()  \tPrediction time:  0.006981849670410156\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.63      0.67        43\n",
      "     neutral       0.76      0.41      0.53        71\n",
      "    positive       0.49      0.86      0.62        50\n",
      "\n",
      "    accuracy                           0.60       164\n",
      "   macro avg       0.65      0.63      0.61       164\n",
      "weighted avg       0.67      0.60      0.60       164\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Testing with real tweets\n",
    "real_tweets = pd.read_json('../data/train/tweets_with_label.json')\n",
    "print(\"Number of Tweets: \", Counter(real_tweets['target']))\n",
    "\n",
    "# Preprocessing\n",
    "real_tweets = real_tweets.rename(columns={'text': 'Text'})\n",
    "real_tweets['Text'] = real_tweets['Text'].str.lower()\n",
    "real_tweets = tweet_pruning(real_tweets, 'amazon', 'AMZN')\n",
    "real_tweets['Text'] = real_tweets['Text'].apply(remove_special_char)\n",
    "\n",
    "for pipe in pipelines:\n",
    "    pipe.fit(train_data['text'], train_data['target'])\n",
    "    \n",
    "    t0 = time.time()    \n",
    "    predicted = pipe.predict(real_tweets['Text'].values)\n",
    "    t1 = time.time()\n",
    "    t = (t1-t0)\n",
    "    \n",
    "    print(\"\\n Evaluation: \", pipe['clf'], \" \\tPrediction time: \", t)\n",
    "    print(metrics.classification_report(real_tweets['target'].values, predicted, target_names=[\"negative\", \"neutral\", \"positive\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0007fbd9",
   "metadata": {},
   "source": [
    "XGBoost Classifier has the best performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "21248433",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../model/sentiment_classifier.pkl']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the classifier\n",
    "filename = '../model/sentiment_classifier.pkl'\n",
    "joblib.dump(pipelines[1], filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
