{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "19228a14",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression, Lasso, ElasticNet\n",
    "from sklearn.metrics import accuracy_score, mean_absolute_error, r2_score, mean_squared_error, mean_absolute_percentage_error\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b95fb5ed",
   "metadata": {},
   "source": [
    "First, we’ll identify a target that we’re trying to predict. Our target will be if the next close price will go up or down tomorrow. If the price went up, the target will be 1.0, and if it went down, the target will be 0.0.\n",
    "\n",
    "EMA explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "533da95b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prev Open</th>\n",
       "      <th>Prev High</th>\n",
       "      <th>Prev Low</th>\n",
       "      <th>Prev Close</th>\n",
       "      <th>Prev Volume</th>\n",
       "      <th>Prev S&amp;P 500 Open</th>\n",
       "      <th>Prev S&amp;P 500 Close</th>\n",
       "      <th>Label</th>\n",
       "      <th>10 Days EMA</th>\n",
       "      <th>5 Days EMA</th>\n",
       "      <th>3 Days EMA</th>\n",
       "      <th>S&amp;P 500 10 Days EMA</th>\n",
       "      <th>S&amp;P 500 5 Days EMA</th>\n",
       "      <th>S&amp;P 500 3 Days EMA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>267.839996</td>\n",
       "      <td>268.809998</td>\n",
       "      <td>267.399994</td>\n",
       "      <td>268.769989</td>\n",
       "      <td>86655700.0</td>\n",
       "      <td>267.839996</td>\n",
       "      <td>268.769989</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.930</td>\n",
       "      <td>0.930</td>\n",
       "      <td>0.930</td>\n",
       "      <td>0.930</td>\n",
       "      <td>0.930</td>\n",
       "      <td>0.930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>268.959991</td>\n",
       "      <td>270.640015</td>\n",
       "      <td>268.959991</td>\n",
       "      <td>270.470001</td>\n",
       "      <td>90070400.0</td>\n",
       "      <td>268.959991</td>\n",
       "      <td>270.470001</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.035</td>\n",
       "      <td>1.123</td>\n",
       "      <td>1.220</td>\n",
       "      <td>1.035</td>\n",
       "      <td>1.123</td>\n",
       "      <td>1.220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>271.200012</td>\n",
       "      <td>272.160004</td>\n",
       "      <td>270.540009</td>\n",
       "      <td>271.609985</td>\n",
       "      <td>80636400.0</td>\n",
       "      <td>271.200012</td>\n",
       "      <td>271.609985</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.922</td>\n",
       "      <td>0.886</td>\n",
       "      <td>0.815</td>\n",
       "      <td>0.922</td>\n",
       "      <td>0.886</td>\n",
       "      <td>0.815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>272.510010</td>\n",
       "      <td>273.559998</td>\n",
       "      <td>271.950012</td>\n",
       "      <td>273.420013</td>\n",
       "      <td>83524000.0</td>\n",
       "      <td>272.510010</td>\n",
       "      <td>273.420013</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.920</td>\n",
       "      <td>0.894</td>\n",
       "      <td>0.862</td>\n",
       "      <td>0.920</td>\n",
       "      <td>0.894</td>\n",
       "      <td>0.862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>273.309998</td>\n",
       "      <td>274.100006</td>\n",
       "      <td>272.980011</td>\n",
       "      <td>273.920013</td>\n",
       "      <td>57319200.0</td>\n",
       "      <td>273.309998</td>\n",
       "      <td>273.920013</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.863</td>\n",
       "      <td>0.799</td>\n",
       "      <td>0.736</td>\n",
       "      <td>0.863</td>\n",
       "      <td>0.799</td>\n",
       "      <td>0.736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1525</th>\n",
       "      <td>132.429993</td>\n",
       "      <td>132.630005</td>\n",
       "      <td>130.229996</td>\n",
       "      <td>132.050003</td>\n",
       "      <td>105158200.0</td>\n",
       "      <td>380.589996</td>\n",
       "      <td>381.260010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.138</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.271</td>\n",
       "      <td>0.883</td>\n",
       "      <td>1.396</td>\n",
       "      <td>1.585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1526</th>\n",
       "      <td>129.190002</td>\n",
       "      <td>130.169998</td>\n",
       "      <td>128.500000</td>\n",
       "      <td>128.979996</td>\n",
       "      <td>100384500.0</td>\n",
       "      <td>377.850006</td>\n",
       "      <td>378.690002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.151</td>\n",
       "      <td>-0.018</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.875</td>\n",
       "      <td>1.210</td>\n",
       "      <td>1.213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1527</th>\n",
       "      <td>128.500000</td>\n",
       "      <td>129.690002</td>\n",
       "      <td>126.860001</td>\n",
       "      <td>128.800003</td>\n",
       "      <td>91951100.0</td>\n",
       "      <td>378.890015</td>\n",
       "      <td>378.769989</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.069</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.694</td>\n",
       "      <td>0.767</td>\n",
       "      <td>0.546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1528</th>\n",
       "      <td>128.759995</td>\n",
       "      <td>131.449997</td>\n",
       "      <td>128.490005</td>\n",
       "      <td>130.889999</td>\n",
       "      <td>88636800.0</td>\n",
       "      <td>378.690002</td>\n",
       "      <td>379.790009</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.331</td>\n",
       "      <td>0.769</td>\n",
       "      <td>1.148</td>\n",
       "      <td>0.768</td>\n",
       "      <td>0.878</td>\n",
       "      <td>0.823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1529</th>\n",
       "      <td>130.800003</td>\n",
       "      <td>131.000000</td>\n",
       "      <td>128.759995</td>\n",
       "      <td>128.910004</td>\n",
       "      <td>90221800.0</td>\n",
       "      <td>380.589996</td>\n",
       "      <td>378.459991</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.073</td>\n",
       "      <td>-0.117</td>\n",
       "      <td>-0.371</td>\n",
       "      <td>0.241</td>\n",
       "      <td>-0.125</td>\n",
       "      <td>-0.653</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1530 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Prev Open   Prev High    Prev Low  Prev Close  Prev Volume  \\\n",
       "0     267.839996  268.809998  267.399994  268.769989   86655700.0   \n",
       "1     268.959991  270.640015  268.959991  270.470001   90070400.0   \n",
       "2     271.200012  272.160004  270.540009  271.609985   80636400.0   \n",
       "3     272.510010  273.559998  271.950012  273.420013   83524000.0   \n",
       "4     273.309998  274.100006  272.980011  273.920013   57319200.0   \n",
       "...          ...         ...         ...         ...          ...   \n",
       "1525  132.429993  132.630005  130.229996  132.050003  105158200.0   \n",
       "1526  129.190002  130.169998  128.500000  128.979996  100384500.0   \n",
       "1527  128.500000  129.690002  126.860001  128.800003   91951100.0   \n",
       "1528  128.759995  131.449997  128.490005  130.889999   88636800.0   \n",
       "1529  130.800003  131.000000  128.759995  128.910004   90221800.0   \n",
       "\n",
       "      Prev S&P 500 Open  Prev S&P 500 Close  Label  10 Days EMA  5 Days EMA  \\\n",
       "0            267.839996          268.769989    1.0        0.930       0.930   \n",
       "1            268.959991          270.470001    1.0        1.035       1.123   \n",
       "2            271.200012          271.609985    1.0        0.922       0.886   \n",
       "3            272.510010          273.420013    1.0        0.920       0.894   \n",
       "4            273.309998          273.920013    1.0        0.863       0.799   \n",
       "...                 ...                 ...    ...          ...         ...   \n",
       "1525         380.589996          381.260010    0.0       -0.138       0.079   \n",
       "1526         377.850006          378.690002    0.0       -0.151      -0.018   \n",
       "1527         378.890015          378.769989    1.0       -0.069       0.088   \n",
       "1528         378.690002          379.790009    0.0        0.331       0.769   \n",
       "1529         380.589996          378.459991    0.0       -0.073      -0.117   \n",
       "\n",
       "      3 Days EMA  S&P 500 10 Days EMA  S&P 500 5 Days EMA  S&P 500 3 Days EMA  \n",
       "0          0.930                0.930               0.930               0.930  \n",
       "1          1.220                1.035               1.123               1.220  \n",
       "2          0.815                0.922               0.886               0.815  \n",
       "3          0.862                0.920               0.894               0.862  \n",
       "4          0.736                0.863               0.799               0.736  \n",
       "...          ...                  ...                 ...                 ...  \n",
       "1525       0.271                0.883               1.396               1.585  \n",
       "1526       0.031                0.875               1.210               1.213  \n",
       "1527       0.165                0.694               0.767               0.546  \n",
       "1528       1.148                0.768               0.878               0.823  \n",
       "1529      -0.371                0.241              -0.125              -0.653  \n",
       "\n",
       "[1530 rows x 14 columns]"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "def prepare_stock_data(stock, start_date='2018-01-01', end_date='2021-01-18'):\n",
    "    #df = pd.read_json('../data/historical_data/' + stock + '.json', lines=True)\n",
    "    #df1 = pd.read_json('../data/historical_data/S&P500.json', lines=True)\n",
    "\n",
    "    \n",
    "    df = yf.download(stock, start=start_date, end=end_date)\n",
    "    df1 = yf.download('SPY', start=start_date, end=end_date)\n",
    "    \n",
    "    df.reset_index(inplace=True)\n",
    "    df1.reset_index(inplace=True)\n",
    "    \n",
    "    df1 = df1.rename(columns={'Open': 'S&P 500 Open', 'Close': 'S&P 500 Close'})\n",
    "\n",
    "    # Join dataframes\n",
    "    df = pd.merge(df[['Date', 'Open', 'High', 'Low', 'Close', 'Volume']],\n",
    "                  df1[['Date', 'S&P 500 Open', 'S&P 500 Close']],\n",
    "                  on='Date', how='outer')\n",
    "    \n",
    "    # Set date as index\n",
    "    df['Date'] = df['Date'].astype(str).str.split(' ').str[0]\n",
    "    df = df.set_index('Date')\n",
    "    \n",
    "    # Add label\n",
    "    df['Label'] = df.rolling(2).apply(lambda x: x.iloc[1] > x.iloc[0])['Close']\n",
    "    \n",
    "    # Shift one day, we can not use the future to predict the past\n",
    "    df[['Open', 'High', 'Low', 'Close', 'Volume', 'S&P 500 Open', 'S&P 500 Close']] = df[['Open', 'High', 'Low', 'Close', 'Volume', 'S&P 500 Open', 'S&P 500 Close']].shift(1)\n",
    "    \n",
    "    df = df.rename(columns={'Open': 'Prev Open', 'High': 'Prev High', 'Low': 'Prev Low', \n",
    "                            'Close': 'Prev Close', 'Volume': 'Prev Volume', 'S&P 500 Open': 'Prev S&P 500 Open', \n",
    "                            'S&P 500 Close': 'Prev S&P 500 Close'})\n",
    "    \n",
    "    \n",
    "    # Add sentiment analysis\n",
    "    \n",
    "    # Compute Exponential Mobile Average (EMA) for stock close prices\n",
    "    delta = df['Prev Close'] - df['Prev Open']\n",
    "    df['10 Days EMA'] = np.round(delta.copy().ewm(span=10, adjust=False).mean(), decimals=3)\n",
    "    df['5 Days EMA'] = np.round(delta.copy().ewm(span=5, adjust=False).mean(), decimals=3)\n",
    "    df['3 Days EMA'] = np.round(delta.copy().ewm(span=3, adjust=False).mean(), decimals=3)\n",
    "\n",
    "    delta = df['Prev S&P 500 Close'] - df['Prev S&P 500 Open']\n",
    "    df['S&P 500 10 Days EMA'] = np.round(delta.copy().ewm(span=10, adjust=False).mean(), decimals=3)\n",
    "    df['S&P 500 5 Days EMA'] = np.round(delta.copy().ewm(span=5, adjust=False).mean(), decimals=3)\n",
    "    df['S&P 500 3 Days EMA'] = np.round(delta.copy().ewm(span=3, adjust=False).mean(), decimals=3)\n",
    "\n",
    "    # Drop rows with NaN values\n",
    "    df.dropna(inplace=True)\n",
    "\n",
    "    # Re order columns\n",
    "    #df = df[['Date', 'Stock Trend EMA', 'S&P 500 Trend EMA', 'Label']]\n",
    "\n",
    "    return df\n",
    "\n",
    "df = prepare_stock_data('SPY')\n",
    "#df.append(prepare_stock_data('AMZN'), ignore_index=True)\n",
    "#df.append(prepare_stock_data('GOOGL'), ignore_index=True)\n",
    "#df.append(prepare_stock_data('TSLA'), ignore_index=True)\n",
    "#df.append(prepare_stock_data('MSFT'), ignore_index=True)\n",
    "#df.append(prepare_stock_data('AAPL'), ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de790e62",
   "metadata": {},
   "source": [
    "the training and test set have to follow chronological order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "82c39e7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of train set:  (612, 5)\n",
      "Size of test set:  (153, 5)\n",
      "Size of train set:  (612, 1)\n",
      "Size of test set:  (153, 1)\n"
     ]
    }
   ],
   "source": [
    "predictors = [#'Prev Open', NO\n",
    "              #'Prev High', NO\n",
    "              #'Prev Low', NO\n",
    "              'Prev Close', # SI\n",
    "              'Prev Volume', # SI\n",
    "              '10 Days EMA', # SI\n",
    "              '5 Days EMA', # SI\n",
    "              '3 Days EMA', # SI\n",
    "              #'S&P 500 10 Days EMA', \n",
    "              #'S&P 500 5 Days EMA', \n",
    "              #'S&P 500 3 Days EMA',\n",
    "              #'Prev S&P 500 Open',\n",
    "              #'Prev S&P 500 Close'\n",
    "            ]\n",
    "x_train, x_test, y_train, y_test = train_test_split(df[predictors],\n",
    "                                                    df[['Label']], test_size=.2,\n",
    "                                                    shuffle=True, random_state=0)\n",
    "\n",
    "print('Size of train set: ', x_train.shape)\n",
    "print('Size of test set: ', x_test.shape)\n",
    "print('Size of train set: ', y_train.shape)\n",
    "print('Size of test set: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "e06b8f72",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "max_features must be in (0, n_features]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9904/2613911999.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mrf_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mrf_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mtest_scores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrf_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    440\u001b[0m             \u001b[1;31m# parallel_backend contexts set at a higher level,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    441\u001b[0m             \u001b[1;31m# since correctness does not rely on using threads.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 442\u001b[1;33m             trees = Parallel(\n\u001b[0m\u001b[0;32m    443\u001b[0m                 \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    444\u001b[0m                 \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1041\u001b[0m             \u001b[1;31m# remaining jobs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1042\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1043\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1044\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1045\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    859\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    860\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 861\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    862\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    863\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    777\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 779\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    780\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 211\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    212\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[0;32m    183\u001b[0m             \u001b[0mcurr_sample_weight\u001b[0m \u001b[1;33m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"balanced\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 185\u001b[1;33m         \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    186\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m         \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m   1313\u001b[0m         \"\"\"\n\u001b[0;32m   1314\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1315\u001b[1;33m         super().fit(\n\u001b[0m\u001b[0;32m   1316\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1317\u001b[0m             \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    306\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"max_depth must be greater than zero. \"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    307\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mmax_features\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_features_in_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 308\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"max_features must be in (0, n_features]\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    309\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_leaf_nodes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumbers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIntegral\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m             raise ValueError(\n",
      "\u001b[1;31mValueError\u001b[0m: max_features must be in (0, n_features]"
     ]
    }
   ],
   "source": [
    "grid = {'n_estimators': [200], 'max_depth': [3], 'max_features': [1, 8], 'random_state': [42]}\n",
    "test_scores = []\n",
    "\n",
    "rf_model = RandomForestRegressor()\n",
    "\n",
    "for g in ParameterGrid(grid):\n",
    "    rf_model.set_params(**g) \n",
    "    rf_model.fit(x_train, y_train.values.ravel())\n",
    "    test_scores.append(rf_model.score(x_test, y_test))\n",
    "\n",
    "best_index = np.argmax(test_scores)\n",
    "print(test_scores[best_index], ParameterGrid(grid)[best_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "fe1a40d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spot-Check Algorithms\n",
    "classifiers = [\n",
    "    RandomForestClassifier(n_estimators=200, min_samples_split=200, max_features = 3, random_state=1, max_depth=3),\n",
    "    XGBClassifier(),\n",
    "    AdaBoostClassifier(),\n",
    "    KNeighborsClassifier(3),\n",
    "   # SVC(kernel=\"linear\", C=0.025),\n",
    "   # SVC(gamma=2, C=1),\n",
    "    #GaussianProcessClassifier(1.0 * RBF(1.0)),\n",
    "    DecisionTreeClassifier(max_depth=5)\n",
    "]\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler()),\n",
    "    (\"pca\", PCA())\n",
    "])\n",
    "\n",
    "numeric_features = predictors\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "   transformers=[\n",
    "    ('numeric', numeric_transformer, numeric_features)\n",
    "]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "be0824b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training  RandomForestClassifier(max_depth=3, max_features=3, min_samples_split=200,\n",
      "                       n_estimators=200, random_state=1)\n",
      "Accuracy on test set:  0.5163398692810458\n",
      "Metrics per class on test set:\n",
      "Confusion matrix:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.31      0.06      0.10        69\n",
      "         1.0       0.54      0.89      0.67        84\n",
      "\n",
      "    accuracy                           0.52       153\n",
      "   macro avg       0.42      0.48      0.38       153\n",
      "weighted avg       0.43      0.52      0.41       153\n",
      "\n",
      "[21:46:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Edoardo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training  XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
      "              gamma=0, gpu_id=-1, importance_type=None,\n",
      "              interaction_constraints='', learning_rate=0.300000012,\n",
      "              max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
      "              monotone_constraints='()', n_estimators=100, n_jobs=8,\n",
      "              num_parallel_tree=1, predictor='auto', random_state=0,\n",
      "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
      "              tree_method='exact', validate_parameters=1, verbosity=None)\n",
      "Accuracy on test set:  0.5032679738562091\n",
      "Metrics per class on test set:\n",
      "Confusion matrix:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.44      0.35      0.39        69\n",
      "         1.0       0.54      0.63      0.58        84\n",
      "\n",
      "    accuracy                           0.50       153\n",
      "   macro avg       0.49      0.49      0.48       153\n",
      "weighted avg       0.49      0.50      0.49       153\n",
      "\n",
      "\n",
      "Training  AdaBoostClassifier()\n",
      "Accuracy on test set:  0.45751633986928103\n",
      "Metrics per class on test set:\n",
      "Confusion matrix:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.36      0.26      0.30        69\n",
      "         1.0       0.50      0.62      0.56        84\n",
      "\n",
      "    accuracy                           0.46       153\n",
      "   macro avg       0.43      0.44      0.43       153\n",
      "weighted avg       0.44      0.46      0.44       153\n",
      "\n",
      "\n",
      "Training  KNeighborsClassifier(n_neighbors=3)\n",
      "Accuracy on test set:  0.46405228758169936\n",
      "Metrics per class on test set:\n",
      "Confusion matrix:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.40      0.36      0.38        69\n",
      "         1.0       0.51      0.55      0.53        84\n",
      "\n",
      "    accuracy                           0.46       153\n",
      "   macro avg       0.45      0.45      0.45       153\n",
      "weighted avg       0.46      0.46      0.46       153\n",
      "\n",
      "\n",
      "Training  DecisionTreeClassifier(max_depth=5)\n",
      "Accuracy on test set:  0.49019607843137253\n",
      "Metrics per class on test set:\n",
      "Confusion matrix:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.33      0.13      0.19        69\n",
      "         1.0       0.52      0.79      0.63        84\n",
      "\n",
      "    accuracy                           0.49       153\n",
      "   macro avg       0.43      0.46      0.41       153\n",
      "weighted avg       0.44      0.49      0.43       153\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for classifier in classifiers:  \n",
    "    \n",
    "    pipe = Pipeline(steps = [\n",
    "               ('preprocessor', preprocessor)\n",
    "              ,('classifier', classifier)\n",
    "           ])\n",
    "    \n",
    "    # Train the model\n",
    "    pipe.fit(x_train, y_train.values.ravel())\n",
    "    \n",
    "    # Use model to make predictions\n",
    "    y_pred = pipe.predict(x_test)\n",
    "    \n",
    "    # Evaluate the performance\n",
    "    print(\"\\nTraining \", classifier)\n",
    "    accuracy = accuracy_score(y_pred, y_test)\n",
    "    print(\"Accuracy on test set: \", accuracy)\n",
    "    print(\"Metrics per class on test set:\")\n",
    "\n",
    "    print(\"Confusion matrix:\")\n",
    "    metrics.confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "a106ce6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../model/classification_model.pkl']"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the Model to disk\n",
    "filename = '../model/classification_model.pkl'\n",
    "final_pipe = Pipeline(steps = [\n",
    "               ('preprocessor', preprocessor)\n",
    "              ,('classifier', classifiers[1])\n",
    "           ])\n",
    "joblib.dump(final_pipe, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ead0de7",
   "metadata": {},
   "source": [
    "Evaluate the model using other test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "bf033a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_stock_value(stock):\n",
    "    df = prepare_stock_data(stock)\n",
    "    y_test = df['Label']\n",
    "    \n",
    "    # Load the Regression Model\n",
    "    pipe = joblib.load('../model/classification_model.pkl')\n",
    "    \n",
    "    # Use model to make predictions\n",
    "    y_pred = pipe.predict(df[predictors])\n",
    "\n",
    "    # Evaluate the performance\n",
    "    print(\"\\n Evaluating \", pipe['classifier'])\n",
    "    accuracy = accuracy_score(y_pred, y_test)\n",
    "    print(\"Accuracy on test set: \", accuracy)\n",
    "    print(\"Metrics per class on test set:\")\n",
    "\n",
    "    print(\"Confusion matrix:\")\n",
    "    metrics.confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "e1fb0427",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      " Evaluating  XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
      "              gamma=0, gpu_id=-1, importance_type=None,\n",
      "              interaction_constraints='', learning_rate=0.300000012,\n",
      "              max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
      "              monotone_constraints='()', n_estimators=100, n_jobs=8,\n",
      "              num_parallel_tree=1, predictor='auto', random_state=0,\n",
      "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
      "              tree_method='exact', validate_parameters=1, verbosity=None)\n",
      "Accuracy on test set:  0.5187007874015748\n",
      "Metrics per class on test set:\n",
      "Confusion matrix:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.48      0.20      0.28       481\n",
      "         1.0       0.53      0.80      0.64       535\n",
      "\n",
      "    accuracy                           0.52      1016\n",
      "   macro avg       0.50      0.50      0.46      1016\n",
      "weighted avg       0.51      0.52      0.47      1016\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict_stock_value('TSLA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "d2be8685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      " Evaluating  XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
      "              gamma=0, gpu_id=-1, importance_type=None,\n",
      "              interaction_constraints='', learning_rate=0.300000012,\n",
      "              max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
      "              monotone_constraints='()', n_estimators=100, n_jobs=8,\n",
      "              num_parallel_tree=1, predictor='auto', random_state=0,\n",
      "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
      "              tree_method='exact', validate_parameters=1, verbosity=None)\n",
      "Accuracy on test set:  0.5295275590551181\n",
      "Metrics per class on test set:\n",
      "Confusion matrix:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.47      0.27      0.34       463\n",
      "         1.0       0.55      0.75      0.63       553\n",
      "\n",
      "    accuracy                           0.53      1016\n",
      "   macro avg       0.51      0.51      0.49      1016\n",
      "weighted avg       0.51      0.53      0.50      1016\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict_stock_value('AAPL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "a27ee4f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      " Evaluating  XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
      "              gamma=0, gpu_id=-1, importance_type=None,\n",
      "              interaction_constraints='', learning_rate=0.300000012,\n",
      "              max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
      "              monotone_constraints='()', n_estimators=100, n_jobs=8,\n",
      "              num_parallel_tree=1, predictor='auto', random_state=0,\n",
      "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
      "              tree_method='exact', validate_parameters=1, verbosity=None)\n",
      "Accuracy on test set:  0.5295275590551181\n",
      "Metrics per class on test set:\n",
      "Confusion matrix:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.47      0.18      0.26       466\n",
      "         1.0       0.54      0.82      0.65       550\n",
      "\n",
      "    accuracy                           0.53      1016\n",
      "   macro avg       0.51      0.50      0.46      1016\n",
      "weighted avg       0.51      0.53      0.48      1016\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict_stock_value('GOOGL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "c3ec0572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      " Evaluating  XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
      "              gamma=0, gpu_id=-1, importance_type=None,\n",
      "              interaction_constraints='', learning_rate=0.300000012,\n",
      "              max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
      "              monotone_constraints='()', n_estimators=100, n_jobs=8,\n",
      "              num_parallel_tree=1, predictor='auto', random_state=0,\n",
      "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
      "              tree_method='exact', validate_parameters=1, verbosity=None)\n",
      "Accuracy on test set:  0.5334645669291339\n",
      "Metrics per class on test set:\n",
      "Confusion matrix:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.45      0.24      0.32       448\n",
      "         1.0       0.56      0.76      0.65       568\n",
      "\n",
      "    accuracy                           0.53      1016\n",
      "   macro avg       0.50      0.50      0.48      1016\n",
      "weighted avg       0.51      0.53      0.50      1016\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict_stock_value('MSFT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e420f8cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd27be71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
