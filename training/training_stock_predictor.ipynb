{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19228a14",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression, Lasso, ElasticNet\n",
    "from sklearn.metrics import accuracy_score, mean_absolute_error, r2_score, mean_squared_error, mean_absolute_percentage_error\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b95fb5ed",
   "metadata": {},
   "source": [
    "First, we’ll identify a target that we’re trying to predict. Our target will be if the next close price will go up or down tomorrow. If the price went up, the target will be 1.0, and if it went down, the target will be 0.0.\n",
    "\n",
    "EMA explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "533da95b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prev Open</th>\n",
       "      <th>Prev High</th>\n",
       "      <th>Prev Low</th>\n",
       "      <th>Prev Close</th>\n",
       "      <th>Prev Volume</th>\n",
       "      <th>Prev S&amp;P 500 Open</th>\n",
       "      <th>Prev S&amp;P 500 Close</th>\n",
       "      <th>Label</th>\n",
       "      <th>10 Days EMA</th>\n",
       "      <th>5 Days EMA</th>\n",
       "      <th>3 Days EMA</th>\n",
       "      <th>S&amp;P 500 10 Days EMA</th>\n",
       "      <th>S&amp;P 500 5 Days EMA</th>\n",
       "      <th>S&amp;P 500 3 Days EMA</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-01-04</th>\n",
       "      <td>757.92</td>\n",
       "      <td>758.76</td>\n",
       "      <td>747.70</td>\n",
       "      <td>753.67</td>\n",
       "      <td>3521066.0</td>\n",
       "      <td>2251.57</td>\n",
       "      <td>2257.83</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-4.250</td>\n",
       "      <td>-4.250</td>\n",
       "      <td>-4.250</td>\n",
       "      <td>6.260</td>\n",
       "      <td>6.260</td>\n",
       "      <td>6.260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-05</th>\n",
       "      <td>758.39</td>\n",
       "      <td>759.68</td>\n",
       "      <td>754.20</td>\n",
       "      <td>757.18</td>\n",
       "      <td>2510526.0</td>\n",
       "      <td>2261.60</td>\n",
       "      <td>2270.75</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-3.697</td>\n",
       "      <td>-3.237</td>\n",
       "      <td>-2.730</td>\n",
       "      <td>6.785</td>\n",
       "      <td>7.223</td>\n",
       "      <td>7.705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-06</th>\n",
       "      <td>761.55</td>\n",
       "      <td>782.40</td>\n",
       "      <td>760.26</td>\n",
       "      <td>780.45</td>\n",
       "      <td>5830068.0</td>\n",
       "      <td>2268.18</td>\n",
       "      <td>2269.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.411</td>\n",
       "      <td>4.142</td>\n",
       "      <td>8.085</td>\n",
       "      <td>5.701</td>\n",
       "      <td>5.089</td>\n",
       "      <td>4.263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-09</th>\n",
       "      <td>782.36</td>\n",
       "      <td>799.44</td>\n",
       "      <td>778.48</td>\n",
       "      <td>795.99</td>\n",
       "      <td>5986234.0</td>\n",
       "      <td>2271.14</td>\n",
       "      <td>2276.98</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.815</td>\n",
       "      <td>7.305</td>\n",
       "      <td>10.858</td>\n",
       "      <td>5.726</td>\n",
       "      <td>5.339</td>\n",
       "      <td>5.051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-10</th>\n",
       "      <td>798.00</td>\n",
       "      <td>801.77</td>\n",
       "      <td>791.77</td>\n",
       "      <td>796.92</td>\n",
       "      <td>3446109.0</td>\n",
       "      <td>2273.59</td>\n",
       "      <td>2268.90</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.107</td>\n",
       "      <td>4.510</td>\n",
       "      <td>4.889</td>\n",
       "      <td>3.832</td>\n",
       "      <td>1.996</td>\n",
       "      <td>0.181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-11</th>\n",
       "      <td>3211.71</td>\n",
       "      <td>3233.23</td>\n",
       "      <td>3126.09</td>\n",
       "      <td>3229.72</td>\n",
       "      <td>4375905.0</td>\n",
       "      <td>4655.34</td>\n",
       "      <td>4670.29</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-10.568</td>\n",
       "      <td>-8.592</td>\n",
       "      <td>-2.488</td>\n",
       "      <td>-6.939</td>\n",
       "      <td>-7.771</td>\n",
       "      <td>-2.961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-12</th>\n",
       "      <td>3230.00</td>\n",
       "      <td>3327.00</td>\n",
       "      <td>3214.03</td>\n",
       "      <td>3307.24</td>\n",
       "      <td>3115146.0</td>\n",
       "      <td>4669.14</td>\n",
       "      <td>4713.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.397</td>\n",
       "      <td>20.019</td>\n",
       "      <td>37.376</td>\n",
       "      <td>2.310</td>\n",
       "      <td>9.463</td>\n",
       "      <td>20.484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-13</th>\n",
       "      <td>3331.50</td>\n",
       "      <td>3337.56</td>\n",
       "      <td>3288.34</td>\n",
       "      <td>3304.14</td>\n",
       "      <td>2290851.0</td>\n",
       "      <td>4728.59</td>\n",
       "      <td>4726.35</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.559</td>\n",
       "      <td>4.226</td>\n",
       "      <td>5.008</td>\n",
       "      <td>1.483</td>\n",
       "      <td>5.562</td>\n",
       "      <td>9.122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-14</th>\n",
       "      <td>3305.01</td>\n",
       "      <td>3324.43</td>\n",
       "      <td>3221.82</td>\n",
       "      <td>3224.28</td>\n",
       "      <td>2590941.0</td>\n",
       "      <td>4733.56</td>\n",
       "      <td>4659.02</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-15.135</td>\n",
       "      <td>-24.093</td>\n",
       "      <td>-37.861</td>\n",
       "      <td>-12.340</td>\n",
       "      <td>-21.139</td>\n",
       "      <td>-32.709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-18</th>\n",
       "      <td>3203.00</td>\n",
       "      <td>3245.00</td>\n",
       "      <td>3196.01</td>\n",
       "      <td>3242.76</td>\n",
       "      <td>2298743.0</td>\n",
       "      <td>4637.99</td>\n",
       "      <td>4662.85</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-5.154</td>\n",
       "      <td>-2.809</td>\n",
       "      <td>0.949</td>\n",
       "      <td>-5.576</td>\n",
       "      <td>-5.806</td>\n",
       "      <td>-3.924</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1269 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Prev Open  Prev High  Prev Low  Prev Close  Prev Volume  \\\n",
       "Date                                                                  \n",
       "2017-01-04     757.92     758.76    747.70      753.67    3521066.0   \n",
       "2017-01-05     758.39     759.68    754.20      757.18    2510526.0   \n",
       "2017-01-06     761.55     782.40    760.26      780.45    5830068.0   \n",
       "2017-01-09     782.36     799.44    778.48      795.99    5986234.0   \n",
       "2017-01-10     798.00     801.77    791.77      796.92    3446109.0   \n",
       "...               ...        ...       ...         ...          ...   \n",
       "2022-01-11    3211.71    3233.23   3126.09     3229.72    4375905.0   \n",
       "2022-01-12    3230.00    3327.00   3214.03     3307.24    3115146.0   \n",
       "2022-01-13    3331.50    3337.56   3288.34     3304.14    2290851.0   \n",
       "2022-01-14    3305.01    3324.43   3221.82     3224.28    2590941.0   \n",
       "2022-01-18    3203.00    3245.00   3196.01     3242.76    2298743.0   \n",
       "\n",
       "            Prev S&P 500 Open  Prev S&P 500 Close  Label  10 Days EMA  \\\n",
       "Date                                                                    \n",
       "2017-01-04            2251.57             2257.83    1.0       -4.250   \n",
       "2017-01-05            2261.60             2270.75    1.0       -3.697   \n",
       "2017-01-06            2268.18             2269.00    1.0        0.411   \n",
       "2017-01-09            2271.14             2276.98    1.0        2.815   \n",
       "2017-01-10            2273.59             2268.90    0.0        2.107   \n",
       "...                       ...                 ...    ...          ...   \n",
       "2022-01-11            4655.34             4670.29    1.0      -10.568   \n",
       "2022-01-12            4669.14             4713.07    0.0        5.397   \n",
       "2022-01-13            4728.59             4726.35    0.0       -0.559   \n",
       "2022-01-14            4733.56             4659.02    1.0      -15.135   \n",
       "2022-01-18            4637.99             4662.85    0.0       -5.154   \n",
       "\n",
       "            5 Days EMA  3 Days EMA  S&P 500 10 Days EMA  S&P 500 5 Days EMA  \\\n",
       "Date                                                                          \n",
       "2017-01-04      -4.250      -4.250                6.260               6.260   \n",
       "2017-01-05      -3.237      -2.730                6.785               7.223   \n",
       "2017-01-06       4.142       8.085                5.701               5.089   \n",
       "2017-01-09       7.305      10.858                5.726               5.339   \n",
       "2017-01-10       4.510       4.889                3.832               1.996   \n",
       "...                ...         ...                  ...                 ...   \n",
       "2022-01-11      -8.592      -2.488               -6.939              -7.771   \n",
       "2022-01-12      20.019      37.376                2.310               9.463   \n",
       "2022-01-13       4.226       5.008                1.483               5.562   \n",
       "2022-01-14     -24.093     -37.861              -12.340             -21.139   \n",
       "2022-01-18      -2.809       0.949               -5.576              -5.806   \n",
       "\n",
       "            S&P 500 3 Days EMA  \n",
       "Date                            \n",
       "2017-01-04               6.260  \n",
       "2017-01-05               7.705  \n",
       "2017-01-06               4.263  \n",
       "2017-01-09               5.051  \n",
       "2017-01-10               0.181  \n",
       "...                        ...  \n",
       "2022-01-11              -2.961  \n",
       "2022-01-12              20.484  \n",
       "2022-01-13               9.122  \n",
       "2022-01-14             -32.709  \n",
       "2022-01-18              -3.924  \n",
       "\n",
       "[1269 rows x 14 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "def prepare_stock_data(stock):\n",
    "    df = pd.read_json('../data/historical_data/' + stock + '.json', lines=True)\n",
    "    df1 = pd.read_json('../data/historical_data/S&P500.json', lines=True)\n",
    "    \n",
    "    df1 = df1.rename(columns={'Open': 'S&P 500 Open', 'Close': 'S&P 500 Close'})\n",
    "\n",
    "    # Join dataframes\n",
    "    df = pd.merge(df[['Date', 'Open', 'High', 'Low', 'Close', 'Volume']],\n",
    "                  df1[['Date', 'S&P 500 Open', 'S&P 500 Close']],\n",
    "                  on='Date', how='outer')\n",
    "    \n",
    "    # Set date as index\n",
    "    df['Date'] = df['Date'].astype(str).str.split(' ').str[0]\n",
    "    df = df.set_index('Date')\n",
    "    \n",
    "    # Add label\n",
    "    df['Label'] = df.rolling(2).apply(lambda x: x.iloc[1] > x.iloc[0])['Close']\n",
    "    \n",
    "    # Shift one day, we can not use the future to predict the past\n",
    "    df[['Open', 'High', 'Low', 'Close', 'Volume', 'S&P 500 Open', 'S&P 500 Close']] = df[['Open', 'High', 'Low', 'Close', 'Volume', 'S&P 500 Open', 'S&P 500 Close']].shift(1)\n",
    "    \n",
    "    df = df.rename(columns={'Open': 'Prev Open', 'High': 'Prev High', 'Low': 'Prev Low', \n",
    "                            'Close': 'Prev Close', 'Volume': 'Prev Volume', 'S&P 500 Open': 'Prev S&P 500 Open', \n",
    "                            'S&P 500 Close': 'Prev S&P 500 Close'})\n",
    "    \n",
    "    \n",
    "    # Add sentiment analysis\n",
    "    \n",
    "    # Compute Exponential Mobile Average (EMA) for stock close prices\n",
    "    delta = df['Prev Close'] - df['Prev Open']\n",
    "    df['10 Days EMA'] = np.round(delta.copy().ewm(span=10, adjust=False).mean(), decimals=3)\n",
    "    df['5 Days EMA'] = np.round(delta.copy().ewm(span=5, adjust=False).mean(), decimals=3)\n",
    "    df['3 Days EMA'] = np.round(delta.copy().ewm(span=3, adjust=False).mean(), decimals=3)\n",
    "\n",
    "    delta = df['Prev S&P 500 Close'] - df['Prev S&P 500 Open']\n",
    "    df['S&P 500 10 Days EMA'] = np.round(delta.copy().ewm(span=10, adjust=False).mean(), decimals=3)\n",
    "    df['S&P 500 5 Days EMA'] = np.round(delta.copy().ewm(span=5, adjust=False).mean(), decimals=3)\n",
    "    df['S&P 500 3 Days EMA'] = np.round(delta.copy().ewm(span=3, adjust=False).mean(), decimals=3)\n",
    "\n",
    "    # Drop rows with NaN values\n",
    "    df.dropna(inplace=True)\n",
    "\n",
    "    # Re order columns\n",
    "    #df = df[['Date', 'Stock Trend EMA', 'S&P 500 Trend EMA', 'Label']]\n",
    "\n",
    "    return df\n",
    "\n",
    "df = prepare_stock_data('AMZN')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de790e62",
   "metadata": {},
   "source": [
    "the training and test set have to follow chronological order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82c39e7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of train set:  (1015, 11)\n",
      "Size of test set:  (254, 11)\n",
      "Size of train set:  (1015, 1)\n",
      "Size of test set:  (254, 1)\n"
     ]
    }
   ],
   "source": [
    "predictors = ['Prev Open', \n",
    "              'Prev High', \n",
    "              'Prev Low', \n",
    "              'Prev Close', \n",
    "              'Prev Volume',\n",
    "              '10 Days EMA', \n",
    "              '5 Days EMA', \n",
    "              '3 Days EMA',\n",
    "              'S&P 500 10 Days EMA', \n",
    "              'S&P 500 5 Days EMA', \n",
    "              'S&P 500 3 Days EMA'\n",
    "             # 'Prev S&P 500 Open',\n",
    "             #'Prev S&P 500 Close'\n",
    "            ]\n",
    "x_train, x_test, y_train, y_test = train_test_split(df[predictors],\n",
    "                                                    df[['Label']], test_size=.2,\n",
    "                                                    shuffle=True, random_state=0)\n",
    "\n",
    "print('Size of train set: ', x_train.shape)\n",
    "print('Size of test set: ', x_test.shape)\n",
    "print('Size of train set: ', y_train.shape)\n",
    "print('Size of test set: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e06b8f72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.007278772248345389 {'random_state': 42, 'n_estimators': 200, 'max_features': 2, 'max_depth': 3}\n"
     ]
    }
   ],
   "source": [
    "grid = {'n_estimators': [200], 'max_depth': [3], 'max_features': [2, 8], 'random_state': [42]}\n",
    "test_scores = []\n",
    "\n",
    "rf_model = RandomForestRegressor()\n",
    "\n",
    "for g in ParameterGrid(grid):\n",
    "    rf_model.set_params(**g) \n",
    "    rf_model.fit(x_train, y_train.values.ravel())\n",
    "    test_scores.append(rf_model.score(x_test, y_test))\n",
    "\n",
    "best_index = np.argmax(test_scores)\n",
    "print(test_scores[best_index], ParameterGrid(grid)[best_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe1a40d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spot-Check Algorithms\n",
    "classifiers = [\n",
    "    RandomForestClassifier(n_estimators=200, min_samples_split=200, max_features = 3, random_state=1, max_depth=3),\n",
    "    XGBClassifier(),\n",
    "    AdaBoostClassifier(),\n",
    "    KNeighborsClassifier(3),\n",
    "   # SVC(kernel=\"linear\", C=0.025),\n",
    "   # SVC(gamma=2, C=1),\n",
    "    #GaussianProcessClassifier(1.0 * RBF(1.0)),\n",
    "    DecisionTreeClassifier(max_depth=5)\n",
    "]\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler()),\n",
    "    (\"pca\", PCA())\n",
    "])\n",
    "\n",
    "numeric_features = predictors\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "   transformers=[\n",
    "    ('numeric', numeric_transformer, numeric_features)\n",
    "]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be0824b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training  RandomForestClassifier(max_depth=3, max_features=3, min_samples_split=200,\n",
      "                       n_estimators=200, random_state=1)\n",
      "Accuracy on test set:  0.5393700787401575\n",
      "Metrics per class on test set:\n",
      "Confusion matrix:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.40      0.11      0.17       111\n",
      "         1.0       0.56      0.87      0.68       143\n",
      "\n",
      "    accuracy                           0.54       254\n",
      "   macro avg       0.48      0.49      0.43       254\n",
      "weighted avg       0.49      0.54      0.46       254\n",
      "\n",
      "[20:54:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Edoardo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training  XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
      "              gamma=0, gpu_id=-1, importance_type=None,\n",
      "              interaction_constraints='', learning_rate=0.300000012,\n",
      "              max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
      "              monotone_constraints='()', n_estimators=100, n_jobs=8,\n",
      "              num_parallel_tree=1, predictor='auto', random_state=0,\n",
      "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
      "              tree_method='exact', validate_parameters=1, verbosity=None)\n",
      "Accuracy on test set:  0.531496062992126\n",
      "Metrics per class on test set:\n",
      "Confusion matrix:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.46      0.44      0.45       111\n",
      "         1.0       0.58      0.60      0.59       143\n",
      "\n",
      "    accuracy                           0.53       254\n",
      "   macro avg       0.52      0.52      0.52       254\n",
      "weighted avg       0.53      0.53      0.53       254\n",
      "\n",
      "\n",
      "Training  AdaBoostClassifier()\n",
      "Accuracy on test set:  0.515748031496063\n",
      "Metrics per class on test set:\n",
      "Confusion matrix:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.43      0.35      0.39       111\n",
      "         1.0       0.56      0.64      0.60       143\n",
      "\n",
      "    accuracy                           0.52       254\n",
      "   macro avg       0.50      0.50      0.49       254\n",
      "weighted avg       0.51      0.52      0.51       254\n",
      "\n",
      "\n",
      "Training  KNeighborsClassifier(n_neighbors=3)\n",
      "Accuracy on test set:  0.5196850393700787\n",
      "Metrics per class on test set:\n",
      "Confusion matrix:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.45      0.44      0.45       111\n",
      "         1.0       0.57      0.58      0.58       143\n",
      "\n",
      "    accuracy                           0.52       254\n",
      "   macro avg       0.51      0.51      0.51       254\n",
      "weighted avg       0.52      0.52      0.52       254\n",
      "\n",
      "\n",
      "Training  DecisionTreeClassifier(max_depth=5)\n",
      "Accuracy on test set:  0.5275590551181102\n",
      "Metrics per class on test set:\n",
      "Confusion matrix:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.45      0.36      0.40       111\n",
      "         1.0       0.57      0.66      0.61       143\n",
      "\n",
      "    accuracy                           0.53       254\n",
      "   macro avg       0.51      0.51      0.51       254\n",
      "weighted avg       0.52      0.53      0.52       254\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for classifier in classifiers:  \n",
    "    \n",
    "    pipe = Pipeline(steps = [\n",
    "               ('preprocessor', preprocessor)\n",
    "              ,('classifier', classifier)\n",
    "           ])\n",
    "    \n",
    "    # Train the model\n",
    "    pipe.fit(x_train, y_train.values.ravel())\n",
    "    \n",
    "    # Use model to make predictions\n",
    "    y_pred = pipe.predict(x_test)\n",
    "    \n",
    "    # Evaluate the performance\n",
    "    print(\"\\nTraining \", classifier)\n",
    "    accuracy = accuracy_score(y_pred, y_test)\n",
    "    print(\"Accuracy on test set: \", accuracy)\n",
    "    print(\"Metrics per class on test set:\")\n",
    "\n",
    "    print(\"Confusion matrix:\")\n",
    "    metrics.confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a106ce6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['classification_model.pkl']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the Model to disk\n",
    "filename = 'classification_model.pkl'\n",
    "final_pipe = Pipeline(steps = [\n",
    "               ('preprocessor', preprocessor)\n",
    "              ,('classifier', classifiers[1])\n",
    "           ])\n",
    "joblib.dump(final_pipe, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ead0de7",
   "metadata": {},
   "source": [
    "Evaluate the model using other test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "bf033a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_stock_value(stock):\n",
    "    df = prepare_stock_data(stock)\n",
    "    y_test = df['Label']\n",
    "    \n",
    "    # Load the Regression Model\n",
    "    pipe = joblib.load('classification_model.pkl')\n",
    "    \n",
    "    # Use model to make predictions\n",
    "    y_pred = pipe.predict(df[predictors])\n",
    "\n",
    "    # Evaluate the performance\n",
    "    print(\"\\n Evaluating \", pipe['classifier'])\n",
    "    accuracy = accuracy_score(y_pred, y_test)\n",
    "    print(\"Accuracy on test set: \", accuracy)\n",
    "    print(\"Metrics per class on test set:\")\n",
    "\n",
    "    print(\"Confusion matrix:\")\n",
    "    metrics.confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e1fb0427",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Evaluating  XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
      "              gamma=0, gpu_id=-1, importance_type=None,\n",
      "              interaction_constraints='', learning_rate=0.300000012,\n",
      "              max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
      "              monotone_constraints='()', n_estimators=100, n_jobs=8,\n",
      "              num_parallel_tree=1, predictor='auto', random_state=0,\n",
      "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
      "              tree_method='exact', validate_parameters=1, verbosity=None)\n",
      "Accuracy on test set:  0.4830575256107171\n",
      "Metrics per class on test set:\n",
      "Confusion matrix:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.47      0.77      0.59       601\n",
      "         1.0       0.52      0.22      0.31       668\n",
      "\n",
      "    accuracy                           0.48      1269\n",
      "   macro avg       0.50      0.50      0.45      1269\n",
      "weighted avg       0.50      0.48      0.44      1269\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict_stock_value('TSLA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d2be8685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Evaluating  XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
      "              gamma=0, gpu_id=-1, importance_type=None,\n",
      "              interaction_constraints='', learning_rate=0.300000012,\n",
      "              max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
      "              monotone_constraints='()', n_estimators=100, n_jobs=8,\n",
      "              num_parallel_tree=1, predictor='auto', random_state=0,\n",
      "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
      "              tree_method='exact', validate_parameters=1, verbosity=None)\n",
      "Accuracy on test set:  0.46099290780141844\n",
      "Metrics per class on test set:\n",
      "Confusion matrix:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.46      1.00      0.63       585\n",
      "         1.0       0.00      0.00      0.00       684\n",
      "\n",
      "    accuracy                           0.46      1269\n",
      "   macro avg       0.23      0.50      0.32      1269\n",
      "weighted avg       0.21      0.46      0.29      1269\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Edoardo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Edoardo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Edoardo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "predict_stock_value('AAPL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a27ee4f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Evaluating  XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
      "              gamma=0, gpu_id=-1, importance_type=None,\n",
      "              interaction_constraints='', learning_rate=0.300000012,\n",
      "              max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
      "              monotone_constraints='()', n_estimators=100, n_jobs=8,\n",
      "              num_parallel_tree=1, predictor='auto', random_state=0,\n",
      "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
      "              tree_method='exact', validate_parameters=1, verbosity=None)\n",
      "Accuracy on test set:  0.9085894405043341\n",
      "Metrics per class on test set:\n",
      "Confusion matrix:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.87      0.90       574\n",
      "         1.0       0.90      0.94      0.92       695\n",
      "\n",
      "    accuracy                           0.91      1269\n",
      "   macro avg       0.91      0.91      0.91      1269\n",
      "weighted avg       0.91      0.91      0.91      1269\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict_stock_value('GOOGL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c3ec0572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Evaluating  XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
      "              gamma=0, gpu_id=-1, importance_type=None,\n",
      "              interaction_constraints='', learning_rate=0.300000012,\n",
      "              max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
      "              monotone_constraints='()', n_estimators=100, n_jobs=8,\n",
      "              num_parallel_tree=1, predictor='auto', random_state=0,\n",
      "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
      "              tree_method='exact', validate_parameters=1, verbosity=None)\n",
      "Accuracy on test set:  0.5697399527186762\n",
      "Metrics per class on test set:\n",
      "Confusion matrix:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.57      0.17      0.26       568\n",
      "         1.0       0.57      0.90      0.70       701\n",
      "\n",
      "    accuracy                           0.57      1269\n",
      "   macro avg       0.57      0.53      0.48      1269\n",
      "weighted avg       0.57      0.57      0.50      1269\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict_stock_value('MSFT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e420f8cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd27be71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
